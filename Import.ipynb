{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Import and Cleaning \n",
    "\n",
    "#### Datasets from here: \n",
    "- https://www.census.gov/programs-surveys/sipp/data/datasets/2008-panel/wave-1.html\n",
    "- https://www.census.gov/programs-surveys/sipp/data/datasets/2008-panel/wave-2.html\n",
    "#### Column definition from here: \n",
    "- https://www2.census.gov/programs-surveys/sipp/data/datasets/2008/l08puw1.sas\n",
    "- https://www2.census.gov/programs-surveys/sipp/data/datasets/2008/p08putm1.sas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sas input statement needs to be cleaned by hand: remove all whitespaces and $-signs e.g. replace ' -' with '-'\n",
    "# columns that should be kept, need to be defined by hand as well\n",
    "def import_sipp_data(sas_input_statement, dat_file, columns_keep):\n",
    "    input_dict = np.loadtxt(sas_input_statement, dtype = str)\n",
    "    column_lst = input_dict[:, 0].tolist()\n",
    "    \n",
    "    colspecs = []\n",
    "    for string in input_dict[:, 1]:\n",
    "        tpl_temp = tuple(map(int, string.split('-')))\n",
    "        tpl_temp = (tpl_temp[0]-1, tpl_temp[1]) # second number should also be corrected?\n",
    "        colspecs.append(tpl_temp)\n",
    "    df_raw = pd.read_fwf(dat_file, names=column_lst, colspecs=colspecs)\n",
    "\n",
    "    df = df_raw[columns_keep]\n",
    "    del df_raw\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns core dataset\n",
    "clmn_join = ['SSUID', 'SPANEL', 'SWAVE', 'EPPPNUM']\n",
    "\n",
    "clmn_join_unused = [ 'TFIPSST', 'EOUTCOME', 'SHHADID', 'RFID', 'RFID2', 'EENTAID', 'EPOPSTAT', 'EPPINTVW', 'ESEX', 'ERACE', 'EORIGIN', 'WPFINWGT', 'ERRP', \n",
    "                    'EMS', 'EPNMOM', 'EPNDAD', 'EPNGUARD', 'EPNSPOUS', 'RDESGPNT', 'TAGE', 'EEDUCATE']\n",
    "\n",
    "clmn_general = ['SREFMON', 'EHREFPER', 'RHCALMN', 'RHCALYR', 'TMOVRFLG', 'EHHNUMPP', 'EFSPOUSE', 'RFNKIDS', 'EBORNUS', 'ECITIZEN', 'RENROLL', 'EFKIND', 'RHTYPE', 'EFNP']\n",
    "\n",
    "# make hist for all income categories and combine the small ones into a new 'other' or substract all interesting income streams from total and take the residual.\n",
    "clmn_income = ['TFEARN', 'TFTOTINC', 'TPEARN', 'TPTOTINC', 'THTRNINC', 'THOTHINC', 'ETENURE', 'THPNDIST', 'THSOCSEC', 'THVETS', 'THLUMPSM', 'THAFDC', \n",
    "                'EAST1C', 'THPRPINC', 'TINTINC', 'TDIVINC', 'EAST3B', 'EAST3C', 'EAST3D', 'EAST3E', 'EAST4A' ]\n",
    "\n",
    "clmn_labor = ['EPAYHR1', 'EPAYHR2', 'TPYRATE1', 'TPYRATE2', 'EJBHRS1', 'EJBHRS2', 'EUNION1', 'EUNION2', 'TMLMSUM', 'EDISABL', 'EDISPREV', \n",
    "                'EAWOP', 'EABRE', 'ERSNOWRK', 'EPTRESN', 'EBUSCNTR', 'EJOBCNTR', 'RMWKSAB', 'EPDJBTHN', 'ELKWRK', 'ELAYOFF', 'EHRSALL', 'EMOONLIT', 'RMHRSWK', 'EPTWRK', \n",
    "                'RMESR', 'RMWKWJB', 'RWKSPERM', 'EBNO1', 'EBNO2']\n",
    "\n",
    "columns_core = clmn_join + clmn_join_unused + clmn_general + clmn_income + clmn_labor\n",
    "print('length core columns: ', len(columns_core))\n",
    "\n",
    "# columns topical dataset\n",
    "clmn_join\n",
    "\n",
    "clmn_rebate = ['EREBATE', 'ERBAMTH', 'ERBATAMT', 'ERBATTYP', 'EREBATOC']\n",
    "\n",
    "columns_topical = clmn_join + clmn_rebate\n",
    "print('length topical columns: ', len(columns_topical))\n",
    "\n",
    "# potential columns to add: TMTHRNT (total rent), RHCHANGE(change in HH composition), RFCHANGE(change in family composition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2_core = import_sipp_data('input_core.txt', '/Users/maxweber/Desktop/DataMasterThesis/l08puw2.dat', columns_core)\n",
    "print('w2 core imported')\n",
    "w2_core.to_csv('/Users/maxweber/Desktop/DataMasterThesis/core_w2.csv') \n",
    "print('w2 core exported to csv')\n",
    "\n",
    "w1_core = import_sipp_data('input_core.txt', '/Users/maxweber/Desktop/DataMasterThesis/l08puw1.dat', columns_core)\n",
    "print('w1 core imported')\n",
    "w1_core.to_csv('/Users/maxweber/Desktop/DataMasterThesis/core_w1.csv') \n",
    "print('w1 core exported to csv')\n",
    "\n",
    "w1_topical = import_sipp_data('input_topical_w1.txt', '/Users/maxweber/Desktop/DataMasterThesis/p08putm1.dat', columns_topical)\n",
    "print('w1 topical imported')\n",
    "w1_topical.to_csv('/Users/maxweber/Desktop/DataMasterThesis/topical_w1.csv') \n",
    "print('w1 topical exported to csv')\n",
    "\n",
    "w2_topical = import_sipp_data('input_topical_w2.txt', '/Users/maxweber/Desktop/DataMasterThesis/p08putm2.dat', columns_topical)\n",
    "print('w2 topical imported')\n",
    "w2_topical.to_csv('/Users/maxweber/Desktop/DataMasterThesis/topical_w2.csv') \n",
    "print('w2 topical exported to csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1_core = pd.read_csv('/Users/maxweber/Desktop/DataMasterThesis/core_w1.csv')\n",
    "w2_core = pd.read_csv('/Users/maxweber/Desktop/DataMasterThesis/core_w2.csv')\n",
    "w1_topical = pd.read_csv('/Users/maxweber/Desktop/DataMasterThesis/topical_w1.csv')\n",
    "w2_topical = pd.read_csv('/Users/maxweber/Desktop/DataMasterThesis/topical_w2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(w1_core.shape)\n",
    "print(w1_topical.shape)\n",
    "w1_full = w1_core.merge(w1_topical[clmn_join+clmn_rebate], how = 'left', on = clmn_join)\n",
    "w1_full.shape\n",
    "\n",
    "print(w2_core.shape)\n",
    "print(w2_topical.shape)\n",
    "w2_full = w2_core.merge(w2_topical[clmn_join+clmn_rebate], how = 'left', on = clmn_join)\n",
    "w2_full.shape\n",
    "\n",
    "df = pd.concat([w1_full, w2_full])\n",
    "df.drop('Unnamed: 0', inplace = True, axis=1)\n",
    "\n",
    "df.to_csv('/Users/maxweber/Desktop/DataMasterThesis/full_sipp.csv')\n",
    "print(df.shape)\n",
    "del [w1_core, w2_core, w1_topical, w2_topical]\n",
    "\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "854dd31d8a762741532201a73c102ff97df2aa6d3df808c117025003f269d370"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
